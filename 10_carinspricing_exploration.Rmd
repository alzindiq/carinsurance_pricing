---
title: "GLMs for Car Insurance Pricing: Initial Data Exploration"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "13 July 2016"
output:
  html_document:
    fig_caption: yes
    theme: spacelab #sandstone #spacelab #flatly
    highlight: pygments
    number_sections: TRUE
    toc: TRUE
    toc_depth: 2
    toc_float:
      smooth_scroll: FALSE
  pdf_document: default
---

<!--
(Title:) GLMs for Car Insurance Pricing

Author: Mick Cooney

Date: 2016

Abstract: This document is the first in a series for a project looking
at a simple method for pricing car insurance based on claims
data. This rmarkdown document focuses on loading the initial data and
performing some systematic data exploration and cleaning.

Keywords: car-insurance data-exploration

-->

```{r knit_opts, include = FALSE}
rm(list = ls())

knitr::opts_chunk$set(tidy       = FALSE
                     ,cache      = FALSE
                     ,fig.height =  8
                     ,fig.width  = 11
                     )

library(tidyverse)
library(data.table)
library(dtplyr)

library(GGally)
library(feather)

library(CASdatasets)


options(width            = 90L)

options(datatable.print.nrows      = 10L)
options(datatable.prettyprint.char = 80L)

set.seed(42)

source("custom_functions.R")
```


This document is the first in a series for a project looking at a simple method
for pricing car insurance based on claims data. This rmarkdown document focuses
on loading the initial data and performing some systematic data exploration and
cleaning.



# Load Data


```{r load_data, echo=TRUE}
### Set up the data
data(freMTPLfreq)
data(freMTPLsev)
data(freMTPL2freq)
data(freMTPL2sev)

policy1_dt <- copy(freMTPLfreq)
claims1_dt <- copy(freMTPLsev)
policy2_dt <- copy(freMTPL2freq)
claims2_dt <- copy(freMTPL2sev)

setDT(policy1_dt)
setDT(claims1_dt)
setDT(policy2_dt)
setDT(claims2_dt)

setnames(policy1_dt, c('policy_id','claim_count','exposure','power','car_age'
                      ,'driver_age','brand','fuel','region','density'))
print(policy1_dt)

setnames(claims1_dt, c('policy_id','claim_amount'))
print(claims1_dt)
```


# Initial Data Exploration

Having loaded in the data, we want to look at the basic data types of
the columns, along with row and columns counts. We also look at a
quick summary of the data.

```{r policy_str, echo=TRUE}
glimpse(policy1_dt)

summary(policy1_dt)
```

The categorical variables here are listed as factors so the first
thing I will do is convert them to character strings. Factors can have
some strange 'gotchas' in how they are used, so it is safe to switch
them to character variables at the very start.

*NB:* I will reverse the previous sentiment and leave these variables as factors for now.

```{r convert_factors_strings, echo=TRUE}
### We use data.table ':=' syntax for this as it is fast and easy to
### understand in this case.
###
### For future data manipulation we will use dplyr for its readability.

#policy1_dt[, power  := as.character(power)]
#policy1_dt[, brand  := as.character(brand)]
#policy1_dt[, fuel   := as.character(fuel)]
#policy1_dt[, region := as.character(region)]
```

We now create separate vectors for the numerical and categorical
variables so we can automatically generate different exploratory plots
of the data.

```{r setup_exploration, echo=TRUE}
vars_num <- c('claim_count','exposure','car_age','driver_age','density')

vars_cat <- c('power','brand','fuel','region')
```

## Univariate Data Exploration

We create simple univariate exploratory plots.

### Numeric Variables

We iterate through the numeric variables, looking at a density plot
for each one.

```{r explore_numeric_data, echo=TRUE}
for(plot_var in vars_num) {
    cat(paste0(plot_var, "\n"))

    explore_plot <- ggplot() +
        geom_density(aes(x = policy1_dt[[plot_var]])) +
        xlab(plot_var) +
        ggtitle(paste0("Density Plot for Variable: ", plot_var))

    plot(explore_plot)
}
```

None of these plots seem very useful, so we try the same thing but now
use histograms.


```{r explore_numeric_data_barplots, echo=TRUE}
for(plot_var in vars_num) {
    cat(paste0(plot_var, "\n"))

    explore_plot <- ggplot() +
        geom_histogram(aes(x = policy1_dt[[plot_var]]), bins = 30) +
        xlab(plot_var) +
        ggtitle(paste0("Bar Plot for Variable: ", plot_var))

    plot(explore_plot)
}
```


### Categorical Variables

We now iterate through each of the categorical variables by looking at
boxplots of the counts of the values.

```{r explore_categorical_data, echo=TRUE}
for(plot_var in vars_cat) {
    cat(paste0(plot_var, "\n"))

    explore_plot <- ggplot() +
        geom_bar(aes(x = policy1_dt[[plot_var]])) +
        xlab(plot_var) +
        ggtitle(paste0("Barplot of Counts for Variable: ", plot_var)) +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5))


    plot(explore_plot)
}
```

#### exposure

The `exposure` variable is a bit strange - it seems strange to have
policies whose duration is longer than a year in this book - but
without knowledge of the business it is hard to tell. Let us see how
the exposures that are longer than 1 year are distributed.

```{r plot_long_exposures, echo=TRUE}
ggplot(policy1_dt %>% filter(exposure > 1)) +
    geom_density(aes(x = exposure))
```

We could remove these policies, but I am inclined to leave them in for
the moment at least. We may need to revisit this decision later.


## Bivariate Data Exploration

We first see how a pairs plot looks. The size of the dataset makes
this computationally onerous, so we sample 50,000 data points and
create the pairs plot for those.

```{r plot_pairsplot, echo=TRUE, message=FALSE, fig.width = 20, fig.height=15, cache=TRUE}
pairsplot_count <- 10000

pairsdata_dt <- policy1_dt %>%
    select(-policy_id) %>%
    sample_n(pairsplot_count, replace = FALSE)

ggpairs(pairsdata_dt)
```

### density vs region

Density seems a bit strange, so I want to see how density distributes
across the regions as that also seems to be geographic.

First we look at boxplots:

```{r density_region_boxplot, echo=TRUE}
ggplot(policy1_dt) +
    geom_boxplot(aes(x = region, y = density))
```

Then we do a facetted histogram, facetting by region.

```{r density_region_histplot, echo=TRUE}
ggplot(policy1_dt) +
    geom_histogram(aes(x = density), bins = 50) +
    facet_wrap(~region, scales = 'free', ncol = 2) +
    ggtitle("density Histogram by region")
```

### claim_count vs region

We will look at `claim_count` vs `region` to see if there are any
geographic patterns.

```{r claimcount_region_barplot, echo=TRUE}
ggplot(policy1_dt) +
    geom_bar(aes(x = claim_count)) +
    expand_limits(x = 4) +
    facet_wrap(~region, scales = 'free', ncol = 2) +
    ggtitle("claim_count Barplot by region")
```

We want to normalise these counts so we can see how many claims we get
as a proportion of the policy count in each region, so to do this we
first need to calculate this:

```{r claimprop_region_barplot, echo=TRUE}
policy_region_dt <- policy1_dt %>%
    group_by(region) %>%
    summarise(num_policies = length(policy_id))

policyprop_dt <- policy1_dt %>%
    left_join(policy_region_dt, 'region') %>%
    group_by(region, claim_count) %>%
    summarise(count = length(policy_id)
             ,prop  = length(policy_id) / max(num_policies))

ggplot(policyprop_dt[claim_count > 0]) +
    geom_bar(aes(x = claim_count, y = prop), stat = 'identity') +
    expand_limits(y = 0.05) +
    facet_wrap(~region, ncol = 2) +
    coord_flip() +
    ggtitle("Claim Proportion Barplot by region")
```

We will also facet across the claim count so we can better compare the
values.

```{r claimprop_claimcount_barplot, echo=TRUE}
ggplot(policyprop_dt[claim_count > 0]) +
    geom_bar(aes(x = region, y = prop), stat = 'identity') +
    expand_limits(x = unique(policyprop_dt$region)) +
    facet_wrap(~claim_count, ncol = 2, scales = 'free') +
    ggtitle("Claim Proportion Barplot by claim_count and region")
```



### region vs car_age

We want to see a distribution of `car_age` by region in the data:

```{r region_carage_boxplot, echo=TRUE}
ggplot(policy1_dt) +
    geom_boxplot(aes(x = region, y = car_age)) +
    ggtitle("Boxplot of car_age by region")
```

We may need to filter out cars that are exceptionally old.

## Claim Data

First we look at a histogram of the individual claims without
aggregating them by policy.

```{r plot_claim_histogram, echo=TRUE, message=FALSE}
ggplot(claims1_dt) +
    geom_histogram(aes(x = claim_amount), bins = 50)
```

This does not tell us much due to the skewed nature of the claims, so
we instead look at all claims below EUR 25,000:

```{r plot_claim_histogram_2, echo=TRUE, message=FALSE}
ggplot(claims1_dt[claim_amount < 25000]) +
    geom_histogram(aes(x = claim_amount), bins = 50) +
    scale_x_continuous(labels = scales::dollar)
```

Claims above 25,000 are so skewed that we look at these on a separate
plot with a logscale on the x-axis.

```{r plot_claim_histogram_3, echo=TRUE, message=FALSE}
ggplot(claims1_dt[claim_amount >= 25000]) +
    geom_histogram(aes(x = claim_amount), bins = 50) +
    scale_x_log10(labels = scales::dollar)
```

To get a sense of the skew in terms of the right tail, we look at
a cumulative density plot of the claim amounts:

```{r plot_claims_cuml, echo=TRUE}
ggplot(claims1_dt) +
    geom_line(aes(x = seq_along(claim_amount) / length(claim_amount)
                 ,y = sort(claim_amount))) +
    scale_y_log10(labels = scales::dollar) +
    xlab("Cumulative Probability") +
    ylab("Claim Amount")
```


### Aggregate Claims by Policy

We now add up all the claims on a single policy and treat them
as a single amount.


```{r summarise_claims, echo=TRUE}
claims_amount_dt <- claims1_dt %>%
    group_by(policy_id) %>%
    summarise(num_claim    = length(claim_amount)
             ,total_claims = sum(claim_amount)) %>%
    arrange(-total_claims, -num_claim)

policyclaim_dt <- policy1_dt %>%
    left_join(claims_amount_dt, by = 'policy_id') %>%
    mutate(total_claims = replace(total_claims, is.na(total_claims), 0))
```

Now we look at the total claims per policy.

```{r policy_claimtotal, echo=TRUE}
ggplot(claims_amount_dt) +
    geom_histogram(aes(x = total_claims), bins = 50) +
    scale_x_log10(labels = scales::dollar)
```

We first check that the merge worked properly by ensuring that
`claim_count` and `num_claim` are the same.

```{r check_claim_count, echo=TRUE}
policyclaim_dt %>%
    filter(claim_count != num_claim) %>%
    print
```

We look at the cumulative claims per policy.

```{r plot_claimstotal_cuml, echo=TRUE}
ggplot(claims_amount_dt) +
    geom_line(aes(x = seq_along(total_claims) / length(total_claims)
                 ,y = sort(total_claims))) +
    scale_y_log10(labels = scales::dollar) +
    xlab("Cumulative Probability") +
    ylab("Claim Amount")
```

### claimtotal by region

We do a boxplot of the total claims by region. We first will plot with
all the claims to see if there is a regional pattern in the larger
claims as we expect these amounts will dominate any visuals.

```{r totalamount_region_boxplot, echo=TRUE}
ggplot(policyclaim_dt[total_claims > 0]) +
    geom_boxplot(aes(x = region, y = total_claims)) +
    scale_y_log10(labels = scales::dollar) +
    ggtitle("Boxplot of Total Claims on a Policy by region")
```

We now filter out the larger claims and do a boxplot for claims
between 0 and 50,000.

```{r totalamount_region_standard, echo=TRUE}
ggplot(policyclaim_dt[total_claims > 0 & total_claims < 25000]) +
    geom_boxplot(aes(x = region, y = total_claims)) +
    scale_y_log10(labels = scales::comma) +
    ggtitle("Boxplot of Total Claims on a Policy by region")
```


### Power-law Scaling

We look at the log-log plot of claim size against the cumulative
number of claims of at least the size to investigate if the claim
frequency obeys a power law.

```{r claim_power_law, echo=TRUE}
logclaimsize_seq <- seq(0, 7, by = 0.1)

powerlaw_dt <- data.table(
    logsize = logclaimsize_seq
   ,count   = sapply(logclaimsize_seq, function(iter_m)
                         nrow(claims1_dt[claim_amount > 10^iter_m]))
)

ggplot(powerlaw_dt) +
    geom_line(aes(x = logsize, y = log(count))) +
    xlab("Log of Cumulative Claim Size") +
    ylab("Log of Count")
```

For claims about 1,000 ($\log \text{Claim} = 3$) a straight line could
do a good job of fitting the curve, so we look at that

```{r claim_power_law_line, echo=TRUE}
ggplot(powerlaw_dt[logsize >= 3]) +
    geom_line(aes(x = logsize, y = log(count))) +
    geom_smooth(aes(x = logsize, y = log(count)), method = 'lm', se = TRUE) +
    xlab("Log of Cumulative Claim Size") +
    ylab("Log of Count")
```

Encouraged by the above plots, we will model part of the claim
distribution with a power law - probably to work on the likelihood of
larger claims.


## Univariate Plots Facetted by Claim

Now we split the data into two groups: those policies with no claims
and those with at least one claim. We then create some univariate
plots of the input data and facet one the claim/noclaim variable to
get an idea of any differences between the two groups.

```{r split_data_claim, echo=TRUE}
claim_noclaim_dt <- policyclaim_dt %>%
    mutate(claim = claim_count > 0)
```

Now that we have this data, we do the same thing as before, create the
univariate plots of the categorical and numeric variables, and we
facet on whether or not the policies have had a claim. This allows us
to make direct comparisons across the variables.

As before, we start with the numeric variables first:

```{r facetted_univariate_numeric_plots, echo=TRUE}
for(plot_var in vars_num) {
    cat(paste0(plot_var, "\n"))

    plotdata_dt <- claim_noclaim_dt %>%
        select_(plot_var, "claim") %>%
        mutate_(use_var = plot_var)

    explore_plot <- ggplot(plotdata_dt) +
        geom_histogram(aes(x = use_var), bins = 30) +
        facet_wrap(~claim, scales = 'free_y', nrow = 2) +
        scale_y_continuous(labels = scales::comma) +
        xlab(plot_var) +
        ggtitle(paste0("Claim-facetted Histograms for Variable: ", plot_var))

    plot(explore_plot)
}
```

Apart from the obvious distinction between claim counts, there appears to be very little difference across the two groups, so we take a look at categorical variables.

```{r facetted_univariate_categorical_plots, echo=TRUE}
for(plot_var in vars_cat) {
    cat(paste0(plot_var, "\n"))

    plotdata_dt <- claim_noclaim_dt %>%
        select_(plot_var, "claim") %>%
        mutate_(use_var = plot_var)

    explore_plot <- ggplot(plotdata_dt) +
        geom_bar(aes(x = use_var)) +
        facet_wrap(~claim, scales = 'free_y', nrow = 2) +
        scale_y_continuous(labels = scales::comma) +
        xlab(plot_var) +
        ggtitle(paste0("Claim-facetted Barplots of Counts for Variable: ", plot_var)) +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

    plot(explore_plot)
}
```


# Data Cleaning

We now turn our attention to data cleaning and feature creation in the
data. We do not have any premium information for the policy data, and
may wish to convert some of the features from continuous to
categorical - especially for variables such as age where we expect a
non-linear influence on the output.

We may exclude data from the analysis if they are outliers.

One issue with removing outliers at this stage is that we are not
entirely sure what counts as an outlier. It may be safer for the
moment to leave them in and perhaps filter them out just prior to
modelling when we have a better sense of what to do. We may wish to
keep all the data for moment and split the modelling tasks into
different parts, capturing different aspects of the data in different
ways.

For the moment, we will leave the data intact.


# Feature Creation

We turn our attention to adding new variables to our dataset to assist
with the modelling. Before we do this, we should look at a summary of
the data.

```{r data_summary, echo=TRUE}
summary(policyclaim_dt)
```

From our initial data exploration in the previous document, we have a
few manipulations that may be worthwhile. We will bin some of the
numeric variables, and we might combine a number of levels in some
categorical variables to reduce the amount of work required.


## Binning Continuous Variables

We aggregate a few of the continuous features that are unlikely to
have any kind of linear response in terms of the data: `driver_age`,
`car_age` and `density`.

We have picked a somewhat arbitrary set of cutoffs to discretise the
variables for these three variables and will check their use in the
models we build.

```{r add_policy_vars, echo=TRUE}
policyclaim_dt <- policyclaim_dt %>%
    mutate(cat_driver_age = cut(driver_age, c(17,22,26,42,74,Inf))
          ,cat_car_age    = cut(car_age,    c(0,1,4,15,Inf)
                               ,include.lowest = TRUE)
          ,cat_density    = cut(density, c(0,40,200,500,4500,Inf)
                               ,include.lowest = TRUE)) %>%
    mutate(cat_driver_age = as.character(cat_driver_age)
          ,cat_car_age    = as.character(cat_car_age)
          ,cat_density    = as.character(cat_density))

glimpse(policyclaim_dt)
```

We will attempt to build models using both continuous and binned
versions of this data and compare the performance of them all.


## Aggregative Categorical Levels

A number of our categorical variables have long tails: they have a
reasonable number of values with small counts. This can cause an issue
as parameter estimates for these levels may lack robustness and
uncertainty limits are likely to be wide. To help with this, we often
create a 'catch-all' value and aggregate all levels below a certain
count to be this 'catch-all' value.

### power

```{r power_barplot, echo=TRUE}
ggplot(policyclaim_dt) +
    geom_bar(aes(x = power)) +
    xlab('Value') +
    ggtitle("Barplot of Counts for Variable power")
```

There is quite a long tail for the higher letters, so we redo this
plot showing the total count of the policies as we account for
additional power levels. This should give us a sense for the point at
which we agglomerate the levels into a single value.

```{r aggregate_power_data, echo=TRUE}
plot_dt <- policyclaim_dt %>%
    group_by(power) %>%
    summarise(count = length(policy_id)) %>%
    arrange(-count) %>%
    summarise(power, cumlcount = cumsum(count))

plot_dt$power <- factor(plot_dt$power, levels = plot_dt$power)

ggplot(plot_dt) +
    geom_bar(aes(x = power, y = cumlcount), stat = 'identity')
```

Looking this plot, we see that the levels from $i$ on in the plot can
be aggregated. We combine $(i,k,l,m,o,n)$ into a single level `other`.

```{r combine_power_levels, echo=TRUE}
power_other <- c('i','k','l','m','o','n')

policyclaim_dt <- policyclaim_dt %>%
    mutate(agg_power = ifelse(power %in% power_other, 'other', power))

ggplot(policyclaim_dt) +
    geom_bar(aes(x = agg_power)) +
    ggtitle("Barplot of new variable: agg_power")
```

We may have been slightly too aggressive with this, so just in case,
we create a new variable `agg_power_2` where we keep value $i$
separate and aggregate the others.


```{r combine_power_levels_second, echo=TRUE}
power_other <- c('k','l','m','o','n')

policyclaim_dt <- policyclaim_dt %>%
    mutate(agg_power_2 = ifelse(power %in% power_other, 'other', power))

ggplot(policyclaim_dt) +
    geom_bar(aes(x = agg_power_2)) +
    ggtitle("Barplot of new variable: agg_power_2")

```

`agg_power_2` would appear to be a better aggregation of levels in
terms of balanced counts - though it should be said that this may not
be in anyway good or desirable.


### region

The `region` variable is imbalanced, so we give it similar treatment.

```{r aggregate_region_data, echo=TRUE}
plot_dt <- policyclaim_dt %>%
    group_by(region) %>%
    summarise(count = length(policy_id)) %>%
    arrange(-count) %>%
    summarise(region, cumlcount = cumsum(count))

plot_dt$region <- factor(plot_dt$region, levels = plot_dt$region)

ggplot(plot_dt) +
    geom_bar(aes(x = region, y = cumlcount), stat = 'identity')
```

We will try to aggregate up the last three values: $R25$, $R23$ and $R74$:

```{r combine_region_levels, echo=TRUE}
region_other <- c('R25','R23','R74')

policyclaim_dt <- policyclaim_dt %>%
    mutate(agg_region = ifelse(region %in% region_other, 'other', region))

ggplot(policyclaim_dt) +
    geom_bar(aes(x = agg_region)) +
    ggtitle("Barplot of new variable: agg_region")
```

While not balanced, `agg_region` has much less of a tail. It will be
interesting to see if this aggregation has any effect on model
performance.


# Write to Disk

We have done some chopping and munging with this data, and we wish to
preserve some of this work across the documents so we save them to
disk in both CSV and feather format.

```{r write_data_disk, echo=TRUE, results='hide'}
### We first drop variable num_claim as it repeats claim_count
policyclaim_dt <- policyclaim_dt %>% select(-num_claim)


write_csv(policy1_dt,         path = 'data/policy_data.csv')
write_csv(claims1_dt,         path = 'data/claim_data.csv')
write_csv(policyclaim_dt,     path = 'data/policyclaim_data.csv')

write_rds(policy1_dt,         path = 'data/policy_dt.rds')
write_rds(claims1_dt,         path = 'data/claim_dt.rds')
write_rds(policyclaim_dt,     path = 'data/policyclaim_dt.rds')

write_feather(policy1_dt,     path = 'data/policy_data.feather')
write_feather(claims1_dt,     path = 'data/claim_data.feather')
write_feather(policyclaim_dt, path = 'data/policyclaim_data.feather')
```


# R Environment

```{r show_session_info, echo=TRUE}
sessioninfo::session_info()
```

